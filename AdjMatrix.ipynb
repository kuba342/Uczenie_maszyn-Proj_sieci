{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da5ddf8f-37ce-41e8-ab7b-6596bc28983e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AdjMatrix:\n",
    "    def __init__(self, V):\n",
    "        self.V = V\n",
    "        self.graph = nx.DiGraph()  # Używamy DiGraph dla krawędzi skierowanych\n",
    "        \n",
    "        # Etykieta\n",
    "        self.label = None\n",
    "        \n",
    "        #Metrics\n",
    "        self.density = None\n",
    "        self.averageClustering = None\n",
    "\n",
    "    def addEdge(self, beg, end, weight):\n",
    "        if (beg >= self.V) or (beg < 0) or (end >= self.V) or (end < 0) or (weight < 0):\n",
    "            return False\n",
    "        else:\n",
    "            self.graph.add_edge(beg, end, weight=weight)\n",
    "            self.graph.add_edge(end, beg, weight=weight)\n",
    "        return True\n",
    "\n",
    "    def addDirectedEdge(self, beg, end, weight):\n",
    "        if (beg >= self.V) or (beg < 0) or (end >= self.V) or (end < 0) or (weight < 0):\n",
    "            return False\n",
    "        else:\n",
    "            self.graph.add_edge(beg, end, weight=weight)\n",
    "        return True\n",
    "    \n",
    "    def calculateMetrics(self):\n",
    "        self.density = nx.density(self.graph)\n",
    "        self.averageClustering = nx.average_clustering(self.graph)\n",
    "\n",
    "    def distance(self, beg, end):\n",
    "        return self.graph[beg][end][\"weight\"]\n",
    "\n",
    "    def showGraph(self):\n",
    "        print(\"           \", end=\" \")\n",
    "        for i in range(self.V):\n",
    "            print(f\"{i:7d}\", end=\" \")\n",
    "        print()\n",
    "        print(\"           \", end=\" \")\n",
    "        for i in range(self.V):\n",
    "            print(\"-------\", end=\" \")\n",
    "        print(\"----\")\n",
    "        for i in range(self.V):\n",
    "            print(f\"Node {i:3d}: |\", end=\" \")\n",
    "            for j in range(self.V):\n",
    "                if self.graph.has_edge(i, j):\n",
    "                    weight = self.graph[i][j].get(\"weight\", 0)\n",
    "                    if weight < 0:\n",
    "                        print(f\"{weight:+7.3f}\", end=\" \")\n",
    "                    else:\n",
    "                        print(f\"{weight:7.3f}\", end=\" \")\n",
    "                else:\n",
    "                    print(\"  0.000 \", end=\" \")\n",
    "            print(\"   |\")\n",
    "\n",
    "    def getV(self):\n",
    "        return self.V\n",
    "\n",
    "    def getMatrix(self):\n",
    "        return self.graph\n",
    "\n",
    "    def add_to_edge(self, source, target, weight):\n",
    "        if source < 0 or source >= self.V or target < 0 or target >= self.V:\n",
    "            print(\"Error: Source and target nodes must be within the range [0, num_nodes-1]\")\n",
    "            return\n",
    "\n",
    "        if self.graph.has_edge(source, target):\n",
    "            self.graph[source][target]['weight'] += weight\n",
    "        else:\n",
    "            self.graph.add_edge(source, target, weight=weight)\n",
    "\n",
    "        \n",
    "        \n",
    "    def addVertex(self):\n",
    "        new_vertex = self.V\n",
    "        self.V += 1\n",
    "        self.graph.add_node(new_vertex)  # Dodawanie nowego wierzchołka\n",
    "        for i in range(self.V):\n",
    "            self.graph.add_edge(i, new_vertex, weight=0)\n",
    "            self.graph.add_edge(new_vertex, i, weight=0)\n",
    "\n",
    "        \n",
    "    def display(self):\n",
    "        pos = nx.kamada_kawai_layout(self.graph)  # użyj kamada_kawai_layout do bardziej sensownego układu wierzchołków\n",
    "\n",
    "        # Nodes with labels\n",
    "        nx.draw_networkx_nodes(self.graph, pos, node_size=300)\n",
    "        node_labels = {node: str(node) for node in self.graph.nodes()}\n",
    "        nx.draw_networkx_labels(self.graph, pos, labels=node_labels)\n",
    "\n",
    "        # Edges with weight > 0\n",
    "        edge_labels = {(u, v): d[\"weight\"] for u, v, d in self.graph.edges(data=True) if d.get(\"weight\", 0) > 0}\n",
    "        nx.draw_networkx_edges(self.graph, pos, width=1.0, style=\"solid\", edgelist=edge_labels.keys())\n",
    "\n",
    "        # Edge weight labels\n",
    "        nx.draw_networkx_edge_labels(self.graph, pos, edge_labels=edge_labels)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c0601-dc8b-405f-971a-87a9eec46721",
   "metadata": {},
   "source": [
    "# Przykadowe użycie kodu wyżej\n",
    "Kod na dole gówno robi, ale pokazuje jak działa kod z komórki wyżej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3aace2-a1d2-47a0-9c33-f98f53644a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "V = 5  # Number of vertices\n",
    "my_graph = AdjMatrix(V)\n",
    "# Dodawanie krawędzi z wagami\n",
    "my_graph.addDirectedEdge(0, 1, 5)\n",
    "my_graph.addDirectedEdge(1, 2, 3)\n",
    "my_graph.addDirectedEdge(2, 3, 2)\n",
    "my_graph.addDirectedEdge(3, 0, 1)\n",
    "my_graph.display()\n",
    "my_graph.showGraph()\n",
    "my_graph.calculateMetrics()\n",
    "\n",
    "my_graph.addVertex()  # Dodawanie nowego wierzchołka\n",
    "my_graph.add_to_edge(5,3,100)\n",
    "my_graph.display()\n",
    "my_graph.showGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e9a6f-6a56-4455-b469-e7a583abed3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wczytywanie danych do pamięci\n",
    "Skoro już mamy potrzebne struktury danych, trzeba by jakoś wczytać zbiory danych uczących, które otrzymaliśmy od prowadzącej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2eed6a1-a957-4796-95f2-4bd0068f1ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request-set-0\n",
      "request-set-1\n",
      "request-set-2\n",
      "requests-set-3\n",
      "requests-set-4\n",
      "requests-set-5\n",
      "requests-set-6\n",
      "requests-set-7\n",
      "requests-set-8\n",
      "requests-set-9\n",
      "Liczba grafów w pamięci: 230\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"euro28\"\n",
    "V = 28\n",
    "\n",
    "def is_dict(param):\n",
    "    return isinstance(param, dict)\n",
    "\n",
    "def readResultsContent(content):\n",
    "    data_dict = {} # Słownik\n",
    "    lines = content[1:]\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            key, value = parts\n",
    "            data_dict[int(key)] = float(value)\n",
    "    return data_dict\n",
    "    \n",
    "\n",
    "def countAverage(lines):\n",
    "    suma = 0.0\n",
    "    count = len(lines)\n",
    "    for line in lines:\n",
    "        value = float(line)\n",
    "        suma += value\n",
    "    if count > 0: \n",
    "        average = suma/count\n",
    "        return average\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    \n",
    "def createGraph(files, label):\n",
    "    graph = AdjMatrix(V)\n",
    "    \n",
    "    # Dodawanie krawędzi:\n",
    "    for file in files:\n",
    "        source = int(file[1])\n",
    "        destination = int(file[2])\n",
    "        average = countAverage(file[4:])\n",
    "        graph.add_to_edge(source, destination, average)\n",
    "    \n",
    "    graph.label = label\n",
    "    return graph\n",
    "    \n",
    "def prepareGraphs(simulations, demands_path):\n",
    "    graphs = []\n",
    "    \n",
    "    if is_dict(simulations):\n",
    "        # Na każdą symulację\n",
    "        graph_files = []\n",
    "        prevSim = 0\n",
    "        for simulation, simulation_value in simulations.items():\n",
    "            # Ładowanie simulation grafów\n",
    "            for i in range(0, simulation):\n",
    "                file_name = f\"{i}.txt\"\n",
    "                file_path = os.path.join(demands_path, file_name)\n",
    "                \n",
    "                if (i >= prevSim and simulation != list(simulations.keys())[0]) or (simulation == list(simulations.keys())[0]):\n",
    "                    if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "                        with open(file_path, 'r') as requests:\n",
    "                            lines = requests.readlines()\n",
    "                            graph_files.append(lines)\n",
    "                    else:\n",
    "                        print(f\"Nie znaleziono pliku {file_name} w lokalizacji {demands_path}\")\n",
    "                \n",
    "            ## Tutaj obsługa robienia grafów żeby móc tylko doładowywać w następnych symulacjach\n",
    "            graph = createGraph(graph_files, simulation_value)\n",
    "            graphs.append(graph)\n",
    "            \n",
    "            \n",
    "            prevSim = simulation\n",
    "        \n",
    "    else:\n",
    "        print(\"Nie podano słownika!\")\n",
    "    \n",
    "    return graphs\n",
    "        \n",
    "                    \n",
    "def processFiles(folder_path):\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        request_sets = os.listdir(folder_path)\n",
    "        for request_set in request_sets:\n",
    "            print(request_set)\n",
    "            request_set_path = os.path.join(folder_path, request_set)\n",
    "            files = os.listdir(request_set_path)\n",
    "            demands = None\n",
    "            for file in files:\n",
    "                if file.startswith(\"demand\"):\n",
    "                    demands = os.path.join(request_set_path, file)\n",
    "            \n",
    "            for file in files:\n",
    "                file = os.path.join(request_set_path, file)\n",
    "                if file.endswith(\"active_transceivers.txt\"):\n",
    "                    with open(file, 'r') as active_transceivers_file:\n",
    "                        content = active_transceivers_file.readlines()\n",
    "                        simulations = readResultsContent(content)\n",
    "                    \n",
    "                        ## TUTAJ JEST SŁOWNIK Z ACTIVE_TRANSCEIVERS LICZBA:WYNIK\n",
    "                        ## Wszystko zgodnie z kolumnami\n",
    "                        graphs = prepareGraphs(simulations, demands)\n",
    "                        GRAPHS.extend(graphs)\n",
    "    else:\n",
    "        print(\"Niepoprawna ścieżka!\")\n",
    "    \n",
    "    print(f\"Liczba grafów w pamięci: {len(GRAPHS)}\")\n",
    "\n",
    "GRAPHS = []\n",
    "processFiles(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d960828-3909-4deb-8f56-f94dc944f4c2",
   "metadata": {},
   "source": [
    "# Obliczanie metryk \n",
    "Wywołana metoda na wszystkich grafach oblicza ich metryki na podstawie reprezentacji grafów powstałych z przesłanych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228f7122-316e-469d-add1-bbc048565b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in GRAPHS:\n",
    "    graph.calculateMetrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fb3c9-af1a-4ea9-a8f0-2a394edde996",
   "metadata": {},
   "source": [
    "# Przygotowanie zbioru danych\n",
    "Obiekt \"data\" zawiera w tym kodzie jedynie:\n",
    "* krawędzie, \n",
    "* wagi krawędzi, \n",
    "* globalną etykietę, \n",
    "* globalne cechy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "407bb421-fe07-457b-a059-cbb38f223b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def prepare_dataset():\n",
    "    graph_list = []\n",
    "    \n",
    "    for graph in GRAPHS:\n",
    "        # Dodanie globalnej etykiety (liczba typu float)\n",
    "        label = graph.label\n",
    "        # Dodanie globalnych cech dla grafu\n",
    "        global_feature = []\n",
    "        global_feature.append(graph.density)\n",
    "        global_feature.append(graph.averageClustering)\n",
    "        # Konwersja do PyTorch Geometric Data\n",
    "        edge_index = torch.tensor(list(graph.graph.edges)).t().contiguous()\n",
    "        edge_attr = torch.tensor([graph.graph[i][j]['weight'] for i, j in graph.graph.edges], dtype=torch.float).view(-1, 1)\n",
    "        y = torch.tensor([label], dtype=torch.float).view(1, -1)\n",
    "        global_feature = torch.tensor(global_feature, dtype=torch.float).view(1, -1)\n",
    "        \n",
    "        data = Data(edge_index=edge_index, edge_attr=edge_attr, y=y, global_feature=global_feature)\n",
    "        graph_list.append(data)\n",
    "        \n",
    "    return graph_list\n",
    "\n",
    "dataset = prepare_dataset()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535f1c6-95b6-4cfe-aed1-08904ad2c114",
   "metadata": {},
   "source": [
    "# PODZIAŁ ZBIORU DANYCH NA UCZĄCE I TESTOWE ORAZ ZAPIS DO PLIKÓW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d027a25-c47f-4ec1-8bcd-0ed56a06d275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiory uczący i testowy zostały utworzone i zapisane.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Ustaw seed, aby uzyskać powtarzalne wyniki\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "num_train = int(train_ratio * len(dataset))\n",
    "num_test = len(dataset) - num_train\n",
    "\n",
    "# Podział danych na zbiór uczący i testowy\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "\n",
    "# Zapisz zbiory do plików\n",
    "torch.save(train_dataset, 'train_dataset.pt')\n",
    "torch.save(test_dataset, 'test_dataset.pt')\n",
    "\n",
    "print(\"Zbiory uczący i testowy zostały utworzone i zapisane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3531751d-7d40-48e1-9beb-1913b0e91e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "# Wczytaj zbiory uczący i testowy\n",
    "train_dataset = torch.load('train_dataset.pt')\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfde700-8695-4d9d-9d87-92b4e6b3b96d",
   "metadata": {},
   "source": [
    "# Próba wykorzystania istniejącego modelu RegGNN\n",
    "https://github.com/basiralab/RegGNN/blob/main/proposed_method/RegGNN.py\n",
    "\n",
    "Nasze zadanie opiera się na przygotowaniu modelu rozwiązującego zadanie regresji grafowej, czyli na podstawie grafów, ich cech globalnych i etykiet chcemy prognozować wartość metryki średniej ilości wykorzystanych transceiverów podczas symulacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0453025e-fe07-4e9d-99b6-8267f2ba3ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''RegGNN regression model architecture.\n",
    "\n",
    "torch_geometric needs to be installed.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.dense import DenseGCNConv\n",
    "\n",
    "\n",
    "class RegGNN(nn.Module):\n",
    "    '''Regression using a DenseGCNConv layer from pytorch geometric.\n",
    "\n",
    "       Layers in this model are identical to GCNConv.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(RegGNN, self).__init__()\n",
    "\n",
    "        self.gc1 = DenseGCNConv(nfeat, nhid)\n",
    "        self.gc2 = DenseGCNConv(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "        self.LinearLayer = nn.Linear(nfeat, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.gc1(x, edge_index))\n",
    "\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, edge_index)\n",
    "        x = self.LinearLayer(torch.transpose(x, 2, 1))\n",
    "\n",
    "        return torch.transpose(x, 2, 1)\n",
    "\n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e2be8-cdad-41b8-817f-d243ce53ba37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
