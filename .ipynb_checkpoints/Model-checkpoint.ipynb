{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c871fa1-528b-4309-a1cc-9ad0de00c8fa",
   "metadata": {},
   "source": [
    "# Próba wykorzystania istniejącego modelu RegGNN\n",
    "https://github.com/basiralab/RegGNN/blob/main/proposed_method/RegGNN.py\n",
    "\n",
    "Nasze zadanie opiera się na przygotowaniu modelu rozwiązującego zadanie regresji grafowej, czyli na podstawie grafów, ich cech globalnych i etykiet chcemy prognozować wartość metryki średniej ilości wykorzystanych transceiverów podczas symulacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9deef8a4-17e1-4edd-ba6f-3f19d15a96a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Wczytaj zbiór uczący\n",
    "train_dataset = torch.load('train_dataset.pt')\n",
    "# wczytaj zbiór testowy\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88cbb7-71a2-4e0f-b89f-2758953ecd6f",
   "metadata": {},
   "source": [
    "# Przykładowy model regresyjny Grafowej sieci neuronowej GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea28cb8-2d89-4112-880d-372fd8f142e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)  # Dostosuj global_feature do rozmiaru x\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900c11d2-46cc-4d45-88fb-ba53eced7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jderd\\AppData\\Local\\Temp\\ipykernel_21620\\794946686.py:36: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred, score)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:39<00:00, 69.90s/trial, best loss: 53519.48545837402]\n",
      "Najlepsze hiperparametry: {'dropout': 0.06769502094656675, 'hidden_dim': 192.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# Zdefiniuj funkcję oceny (score function)\n",
    "def objective(params):\n",
    "    hidden_dim = int(params['hidden_dim'])\n",
    "    dropout = params['dropout']\n",
    "\n",
    "    model = GraphRegressionModel(hidden_dim=hidden_dim, dropout=dropout)\n",
    "    \n",
    "    # Definiuj optymalizator, liczbę epok, itp.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 200\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Trening i ewaluacja modelu\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Ewaluacja na zbiorze testowym\n",
    "    test_loss = 0.0  \n",
    "    for data in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += model.loss(output, data.y.view(-1, 1).float()).item()\n",
    "    \n",
    "    # Zwróć funkcję oceny (score)\n",
    "    return test_loss\n",
    "\n",
    "# Przestrzeń poszukiwań dla hyperopt\n",
    "space = {\n",
    "    'hidden_dim': hp.quniform('hidden_dim', 32, 256, 32),  # Przeszukuj wartości co 32\n",
    "    'dropout': hp.uniform('dropout', 0.05, 0.8),\n",
    "}\n",
    "\n",
    "# Minimalizacja funkcji oceny za pomocą algorytmu TPE\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10)  # Dla przykładu ustawiono max_evals na 10\n",
    "print(\"Najlepsze hiperparametry:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e498ea76-9b7d-4e54-9f01-f974f6269914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jderd\\anaconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jderd\\AppData\\Local\\Temp\\ipykernel_29088\\794946686.py:36: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m         output \u001b[38;5;241m=\u001b[39m optimal_model(data)\n\u001b[0;32m     34\u001b[0m         loss \u001b[38;5;241m=\u001b[39m optimal_model\u001b[38;5;241m.\u001b[39mloss(output, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m---> 35\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     36\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     38\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m test_dataset[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Ustawienie optymalnych hiperparametrów\n",
    "#optimal_hidden_dim = int(best['hidden_dim'])\n",
    "#optimal_dropout = best['dropout']\n",
    "\n",
    "optimal_hidden_dim = 192\n",
    "optimal_dropout = 0.06\n",
    "\n",
    "# Inicjalizacja modelu z optymalnymi hiperparametrami\n",
    "optimal_model = GraphRegressionModel(hidden_dim=optimal_hidden_dim, dropout=optimal_dropout)\n",
    "\n",
    "# Definiuj DataLoader dla zbiorów uczącego i testowego\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Definiuj optymalizator, liczbę epok, itp.\n",
    "optimizer = torch.optim.Adam(optimal_model.parameters(), lr=0.001)\n",
    "num_epochs = 500\n",
    "\n",
    "# Listy do śledzenia train loss i test loss\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Trening modelu\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch:\", epoch)\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = optimal_model(data)\n",
    "        loss = optimal_model.loss(output, data.y.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "sample_data = test_dataset[0]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fc4a8c-0a49-4e5e-8fed-c54bb4991be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana wartość: 830.5301513671875\n",
      "Rzeczywista wartość: 860.9299926757812\n"
     ]
    }
   ],
   "source": [
    "sample_data = test_dataset[30]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4e0e9f9-d9b9-487b-a673-1a3ea0cd313c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana wartość: 287.41595458984375\n",
      "Rzeczywista wartość: 286.3299865722656\n"
     ]
    }
   ],
   "source": [
    "sample_data = test_dataset[9]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5e5f93d-8db8-4a92-8058-f4ce2fa5f729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykład 1:\n",
      "Przewidywana wartość: 834.1890869140625\n",
      "Rzeczywista wartość: 874.5499877929688\n",
      "Procentowa jakość regresji: 95.38%\n",
      "\n",
      "Przykład 2:\n",
      "Przewidywana wartość: 576.5999145507812\n",
      "Rzeczywista wartość: 569.8499755859375\n",
      "Procentowa jakość regresji: 98.82%\n",
      "\n",
      "Przykład 3:\n",
      "Przewidywana wartość: 461.2392578125\n",
      "Rzeczywista wartość: 450.54998779296875\n",
      "Procentowa jakość regresji: 97.63%\n",
      "\n",
      "Przykład 4:\n",
      "Przewidywana wartość: 881.8521118164062\n",
      "Rzeczywista wartość: 839.4600219726562\n",
      "Procentowa jakość regresji: 94.95%\n",
      "\n",
      "Przykład 5:\n",
      "Przewidywana wartość: 702.5387573242188\n",
      "Rzeczywista wartość: 705.010009765625\n",
      "Procentowa jakość regresji: 99.65%\n",
      "\n",
      "Przykład 6:\n",
      "Przewidywana wartość: 687.1488037109375\n",
      "Rzeczywista wartość: 697.9400024414062\n",
      "Procentowa jakość regresji: 98.45%\n",
      "\n",
      "Przykład 7:\n",
      "Przewidywana wartość: 870.410400390625\n",
      "Rzeczywista wartość: 854.9099731445312\n",
      "Procentowa jakość regresji: 98.19%\n",
      "\n",
      "Przykład 8:\n",
      "Przewidywana wartość: 800.1185913085938\n",
      "Rzeczywista wartość: 813.02001953125\n",
      "Procentowa jakość regresji: 98.41%\n",
      "\n",
      "Przykład 9:\n",
      "Przewidywana wartość: 313.1221618652344\n",
      "Rzeczywista wartość: 286.0299987792969\n",
      "Procentowa jakość regresji: 90.53%\n",
      "\n",
      "Przykład 10:\n",
      "Przewidywana wartość: 287.41595458984375\n",
      "Rzeczywista wartość: 286.3299865722656\n",
      "Procentowa jakość regresji: 99.62%\n",
      "\n",
      "Przykład 11:\n",
      "Przewidywana wartość: 636.6835327148438\n",
      "Rzeczywista wartość: 673.02001953125\n",
      "Procentowa jakość regresji: 94.60%\n",
      "\n",
      "Przykład 12:\n",
      "Przewidywana wartość: 188.58734130859375\n",
      "Rzeczywista wartość: 198.0\n",
      "Procentowa jakość regresji: 95.25%\n",
      "\n",
      "Przykład 13:\n",
      "Przewidywana wartość: 868.7130737304688\n",
      "Rzeczywista wartość: 863.3800048828125\n",
      "Procentowa jakość regresji: 99.38%\n",
      "\n",
      "Przykład 14:\n",
      "Przewidywana wartość: 262.591552734375\n",
      "Rzeczywista wartość: 240.9499969482422\n",
      "Procentowa jakość regresji: 91.02%\n",
      "\n",
      "Przykład 15:\n",
      "Przewidywana wartość: 245.71690368652344\n",
      "Rzeczywista wartość: 238.02999877929688\n",
      "Procentowa jakość regresji: 96.77%\n",
      "\n",
      "Przykład 16:\n",
      "Przewidywana wartość: 798.134765625\n",
      "Rzeczywista wartość: 855.3099975585938\n",
      "Procentowa jakość regresji: 93.32%\n",
      "\n",
      "Przykład 17:\n",
      "Przewidywana wartość: 389.4044494628906\n",
      "Rzeczywista wartość: 367.8999938964844\n",
      "Procentowa jakość regresji: 94.15%\n",
      "\n",
      "Przykład 18:\n",
      "Przewidywana wartość: 602.3310546875\n",
      "Rzeczywista wartość: 620.719970703125\n",
      "Procentowa jakość regresji: 97.04%\n",
      "\n",
      "Przykład 19:\n",
      "Przewidywana wartość: 843.0896606445312\n",
      "Rzeczywista wartość: 828.6599731445312\n",
      "Procentowa jakość regresji: 98.26%\n",
      "\n",
      "Przykład 20:\n",
      "Przewidywana wartość: 488.8903503417969\n",
      "Rzeczywista wartość: 485.5199890136719\n",
      "Procentowa jakość regresji: 99.31%\n",
      "\n",
      "Przykład 21:\n",
      "Przewidywana wartość: 294.8210144042969\n",
      "Rzeczywista wartość: 291.5199890136719\n",
      "Procentowa jakość regresji: 98.87%\n",
      "\n",
      "Przykład 22:\n",
      "Przewidywana wartość: 346.6177978515625\n",
      "Rzeczywista wartość: 325.3299865722656\n",
      "Procentowa jakość regresji: 93.46%\n",
      "\n",
      "Przykład 23:\n",
      "Przewidywana wartość: 409.6965026855469\n",
      "Rzeczywista wartość: 382.94000244140625\n",
      "Procentowa jakość regresji: 93.01%\n",
      "\n",
      "Przykład 24:\n",
      "Przewidywana wartość: 438.1330871582031\n",
      "Rzeczywista wartość: 416.5400085449219\n",
      "Procentowa jakość regresji: 94.82%\n",
      "\n",
      "Przykład 25:\n",
      "Przewidywana wartość: 906.2385864257812\n",
      "Rzeczywista wartość: 895.22998046875\n",
      "Procentowa jakość regresji: 98.77%\n",
      "\n",
      "Przykład 26:\n",
      "Przewidywana wartość: 958.824462890625\n",
      "Rzeczywista wartość: 903.760009765625\n",
      "Procentowa jakość regresji: 93.91%\n",
      "\n",
      "Przykład 27:\n",
      "Przewidywana wartość: 827.7879638671875\n",
      "Rzeczywista wartość: 816.4500122070312\n",
      "Procentowa jakość regresji: 98.61%\n",
      "\n",
      "Przykład 28:\n",
      "Przewidywana wartość: 862.19580078125\n",
      "Rzeczywista wartość: 858.4500122070312\n",
      "Procentowa jakość regresji: 99.56%\n",
      "\n",
      "Przykład 29:\n",
      "Przewidywana wartość: 787.8715209960938\n",
      "Rzeczywista wartość: 806.6900024414062\n",
      "Procentowa jakość regresji: 97.67%\n",
      "\n",
      "Przykład 30:\n",
      "Przewidywana wartość: 210.07562255859375\n",
      "Rzeczywista wartość: 200.39999389648438\n",
      "Procentowa jakość regresji: 95.17%\n",
      "\n",
      "Przykład 31:\n",
      "Przewidywana wartość: 830.5301513671875\n",
      "Rzeczywista wartość: 860.9299926757812\n",
      "Procentowa jakość regresji: 96.47%\n",
      "\n",
      "Przykład 32:\n",
      "Przewidywana wartość: 891.6096801757812\n",
      "Rzeczywista wartość: 898.5999755859375\n",
      "Procentowa jakość regresji: 99.22%\n",
      "\n",
      "Przykład 33:\n",
      "Przewidywana wartość: 800.7440795898438\n",
      "Rzeczywista wartość: 786.8599853515625\n",
      "Procentowa jakość regresji: 98.24%\n",
      "\n",
      "Przykład 34:\n",
      "Przewidywana wartość: 477.6459045410156\n",
      "Rzeczywista wartość: 463.6000061035156\n",
      "Procentowa jakość regresji: 96.97%\n",
      "\n",
      "Przykład 35:\n",
      "Przewidywana wartość: 664.0677490234375\n",
      "Rzeczywista wartość: 640.3599853515625\n",
      "Procentowa jakość regresji: 96.30%\n",
      "\n",
      "Przykład 36:\n",
      "Przewidywana wartość: 936.4877319335938\n",
      "Rzeczywista wartość: 979.5999755859375\n",
      "Procentowa jakość regresji: 95.60%\n",
      "\n",
      "Przykład 37:\n",
      "Przewidywana wartość: 195.85824584960938\n",
      "Rzeczywista wartość: 197.47000122070312\n",
      "Procentowa jakość regresji: 99.18%\n",
      "\n",
      "Przykład 38:\n",
      "Przewidywana wartość: 703.8026733398438\n",
      "Rzeczywista wartość: 678.4500122070312\n",
      "Procentowa jakość regresji: 96.26%\n",
      "\n",
      "Przykład 39:\n",
      "Przewidywana wartość: 400.3258056640625\n",
      "Rzeczywista wartość: 368.6300048828125\n",
      "Procentowa jakość regresji: 91.40%\n",
      "\n",
      "Przykład 40:\n",
      "Przewidywana wartość: 243.45547485351562\n",
      "Rzeczywista wartość: 246.77999877929688\n",
      "Procentowa jakość regresji: 98.65%\n",
      "\n",
      "Przykład 41:\n",
      "Przewidywana wartość: 599.9741821289062\n",
      "Rzeczywista wartość: 588.5499877929688\n",
      "Procentowa jakość regresji: 98.06%\n",
      "\n",
      "Przykład 42:\n",
      "Przewidywana wartość: 873.4169921875\n",
      "Rzeczywista wartość: 891.1699829101562\n",
      "Procentowa jakość regresji: 98.01%\n",
      "\n",
      "Przykład 43:\n",
      "Przewidywana wartość: 961.0892944335938\n",
      "Rzeczywista wartość: 916.719970703125\n",
      "Procentowa jakość regresji: 95.16%\n",
      "\n",
      "Przykład 44:\n",
      "Przewidywana wartość: 574.576904296875\n",
      "Rzeczywista wartość: 551.02001953125\n",
      "Procentowa jakość regresji: 95.72%\n",
      "\n",
      "Przykład 45:\n",
      "Przewidywana wartość: 511.0352783203125\n",
      "Rzeczywista wartość: 501.6300048828125\n",
      "Procentowa jakość regresji: 98.13%\n",
      "\n",
      "Przykład 46:\n",
      "Przewidywana wartość: 754.2468872070312\n",
      "Rzeczywista wartość: 778.0399780273438\n",
      "Procentowa jakość regresji: 96.94%\n",
      "\n",
      "Średnia procentowa jakość regresji dla wszystkich przykładów: 96.63%\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = 0.0\n",
    "\n",
    "# Iteracja przez cały zbiór testowy\n",
    "for i, sample_data in enumerate(test_dataset):\n",
    "    # Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "    optimal_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = optimal_model(sample_data)[0][0].item()\n",
    "    \n",
    "    # Wyświetlenie wyników\n",
    "    print(f\"Przykład {i + 1}:\")\n",
    "    print(\"Przewidywana wartość:\", prediction)\n",
    "    print(\"Rzeczywista wartość:\", sample_data.y.item())\n",
    "    \n",
    "    # Obliczenie procentowej jakości regresji\n",
    "    actual_value = sample_data.y.item()\n",
    "    accuracy = 100 * (1 - abs(prediction - actual_value) / actual_value)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "    print(f\"Procentowa jakość regresji: {accuracy:.2f}%\\n\")\n",
    "\n",
    "# Obliczenie średniej jakości procentowej\n",
    "average_accuracy = total_accuracy / len(test_dataset)\n",
    "print(f\"Średnia procentowa jakość regresji dla wszystkich przykładów: {average_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175333d-a83a-4a99-a172-800e4856b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
