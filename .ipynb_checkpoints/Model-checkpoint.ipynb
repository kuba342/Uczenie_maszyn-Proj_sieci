{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c871fa1-528b-4309-a1cc-9ad0de00c8fa",
   "metadata": {},
   "source": [
    "# Próba wykorzystania istniejącego modelu RegGNN\n",
    "https://github.com/basiralab/RegGNN/blob/main/proposed_method/RegGNN.py\n",
    "\n",
    "Nasze zadanie opiera się na przygotowaniu modelu rozwiązującego zadanie regresji grafowej, czyli na podstawie grafów, ich cech globalnych i etykiet chcemy prognozować wartość metryki średniej ilości wykorzystanych transceiverów podczas symulacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9deef8a4-17e1-4edd-ba6f-3f19d15a96a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Wczytaj zbiór uczący\n",
    "train_dataset = torch.load('train_dataset.pt')\n",
    "# wczytaj zbiór testowy\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88cbb7-71a2-4e0f-b89f-2758953ecd6f",
   "metadata": {},
   "source": [
    "# Przykładowy model regresyjny Grafowej sieci neuronowej GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c9d06d-d65d-4fd8-be44-9eff45edd0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "class GINRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GINRegression, self).__init__()\n",
    "\n",
    "        # GINConv layers\n",
    "        self.conv1 = GINConv(nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        ), train_eps=True)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GINConv(nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ), train_eps=True))\n",
    "\n",
    "        # Fully connected layers for regression\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)  # Dodane 2 na cechy globalne\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        density, avg_clustering = data.global_feature[:, 0], data.global_feature[:, 1]  # Wyciąganie globalnych cech\n",
    "\n",
    "        # GINConv layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "\n",
    "        # Global pooling and fully connected layers with global features\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = torch.cat([x, density.view(-1, 1), avg_clustering.view(-1, 1)], dim=1)  # Dodane globalne cechy\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea28cb8-2d89-4112-880d-372fd8f142e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)  # Dostosuj global_feature do rozmiaru x\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900c11d2-46cc-4d45-88fb-ba53eced7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jderd\\AppData\\Local\\Temp\\ipykernel_21620\\794946686.py:36: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred, score)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:39<00:00, 69.90s/trial, best loss: 53519.48545837402]\n",
      "Najlepsze hiperparametry: {'dropout': 0.06769502094656675, 'hidden_dim': 192.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# Zdefiniuj funkcję oceny (score function)\n",
    "def objective(params):\n",
    "    hidden_dim = int(params['hidden_dim'])\n",
    "    dropout = params['dropout']\n",
    "\n",
    "    model = GraphRegressionModel(hidden_dim=hidden_dim, dropout=dropout)\n",
    "    \n",
    "    # Definiuj optymalizator, liczbę epok, itp.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 200\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Trening i ewaluacja modelu\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Ewaluacja na zbiorze testowym\n",
    "    test_loss = 0.0  \n",
    "    for data in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += model.loss(output, data.y.view(-1, 1).float()).item()\n",
    "    \n",
    "    # Zwróć funkcję oceny (score)\n",
    "    return test_loss\n",
    "\n",
    "# Przestrzeń poszukiwań dla hyperopt\n",
    "space = {\n",
    "    'hidden_dim': hp.quniform('hidden_dim', 32, 256, 32),  # Przeszukuj wartości co 32\n",
    "    'dropout': hp.uniform('dropout', 0.05, 0.8),\n",
    "}\n",
    "\n",
    "# Minimalizacja funkcji oceny za pomocą algorytmu TPE\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10)  # Dla przykładu ustawiono max_evals na 10\n",
    "print(\"Najlepsze hiperparametry:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e498ea76-9b7d-4e54-9f01-f974f6269914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jderd\\AppData\\Local\\Temp\\ipykernel_21620\\794946686.py:36: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Epoch: 30\n",
      "Epoch: 31\n",
      "Epoch: 32\n",
      "Epoch: 33\n",
      "Epoch: 34\n",
      "Epoch: 35\n",
      "Epoch: 36\n",
      "Epoch: 37\n",
      "Epoch: 38\n",
      "Epoch: 39\n",
      "Epoch: 40\n",
      "Epoch: 41\n",
      "Epoch: 42\n",
      "Epoch: 43\n",
      "Epoch: 44\n",
      "Epoch: 45\n",
      "Epoch: 46\n",
      "Epoch: 47\n",
      "Epoch: 48\n",
      "Epoch: 49\n",
      "Epoch: 50\n",
      "Epoch: 51\n",
      "Epoch: 52\n",
      "Epoch: 53\n",
      "Epoch: 54\n",
      "Epoch: 55\n",
      "Epoch: 56\n",
      "Epoch: 57\n",
      "Epoch: 58\n",
      "Epoch: 59\n",
      "Epoch: 60\n",
      "Epoch: 61\n",
      "Epoch: 62\n",
      "Epoch: 63\n",
      "Epoch: 64\n",
      "Epoch: 65\n",
      "Epoch: 66\n",
      "Epoch: 67\n",
      "Epoch: 68\n",
      "Epoch: 69\n",
      "Epoch: 70\n",
      "Epoch: 71\n",
      "Epoch: 72\n",
      "Epoch: 73\n",
      "Epoch: 74\n",
      "Epoch: 75\n",
      "Epoch: 76\n",
      "Epoch: 77\n",
      "Epoch: 78\n",
      "Epoch: 79\n",
      "Epoch: 80\n",
      "Epoch: 81\n",
      "Epoch: 82\n",
      "Epoch: 83\n",
      "Epoch: 84\n",
      "Epoch: 85\n",
      "Epoch: 86\n",
      "Epoch: 87\n",
      "Epoch: 88\n",
      "Epoch: 89\n",
      "Epoch: 90\n",
      "Epoch: 91\n",
      "Epoch: 92\n",
      "Epoch: 93\n",
      "Epoch: 94\n",
      "Epoch: 95\n",
      "Epoch: 96\n",
      "Epoch: 97\n",
      "Epoch: 98\n",
      "Epoch: 99\n",
      "Epoch: 100\n",
      "Epoch: 101\n",
      "Epoch: 102\n",
      "Epoch: 103\n",
      "Epoch: 104\n",
      "Epoch: 105\n",
      "Epoch: 106\n",
      "Epoch: 107\n",
      "Epoch: 108\n",
      "Epoch: 109\n",
      "Epoch: 110\n",
      "Epoch: 111\n",
      "Epoch: 112\n",
      "Epoch: 113\n",
      "Epoch: 114\n",
      "Epoch: 115\n",
      "Epoch: 116\n",
      "Epoch: 117\n",
      "Epoch: 118\n",
      "Epoch: 119\n",
      "Epoch: 120\n",
      "Epoch: 121\n",
      "Epoch: 122\n",
      "Epoch: 123\n",
      "Epoch: 124\n",
      "Epoch: 125\n",
      "Epoch: 126\n",
      "Epoch: 127\n",
      "Epoch: 128\n",
      "Epoch: 129\n",
      "Epoch: 130\n",
      "Epoch: 131\n",
      "Epoch: 132\n",
      "Epoch: 133\n",
      "Epoch: 134\n",
      "Epoch: 135\n",
      "Epoch: 136\n",
      "Epoch: 137\n",
      "Epoch: 138\n",
      "Epoch: 139\n",
      "Epoch: 140\n",
      "Epoch: 141\n",
      "Epoch: 142\n",
      "Epoch: 143\n",
      "Epoch: 144\n",
      "Epoch: 145\n",
      "Epoch: 146\n",
      "Epoch: 147\n",
      "Epoch: 148\n",
      "Epoch: 149\n",
      "Epoch: 150\n",
      "Epoch: 151\n",
      "Epoch: 152\n",
      "Epoch: 153\n",
      "Epoch: 154\n",
      "Epoch: 155\n",
      "Epoch: 156\n",
      "Epoch: 157\n",
      "Epoch: 158\n",
      "Epoch: 159\n",
      "Epoch: 160\n",
      "Epoch: 161\n",
      "Epoch: 162\n",
      "Epoch: 163\n",
      "Epoch: 164\n",
      "Epoch: 165\n",
      "Epoch: 166\n",
      "Epoch: 167\n",
      "Epoch: 168\n",
      "Epoch: 169\n",
      "Epoch: 170\n",
      "Epoch: 171\n",
      "Epoch: 172\n",
      "Epoch: 173\n",
      "Epoch: 174\n",
      "Epoch: 175\n",
      "Epoch: 176\n",
      "Epoch: 177\n",
      "Epoch: 178\n",
      "Epoch: 179\n",
      "Epoch: 180\n",
      "Epoch: 181\n",
      "Epoch: 182\n",
      "Epoch: 183\n",
      "Epoch: 184\n",
      "Epoch: 185\n",
      "Epoch: 186\n",
      "Epoch: 187\n",
      "Epoch: 188\n",
      "Epoch: 189\n",
      "Epoch: 190\n",
      "Epoch: 191\n",
      "Epoch: 192\n",
      "Epoch: 193\n",
      "Epoch: 194\n",
      "Epoch: 195\n",
      "Epoch: 196\n",
      "Epoch: 197\n",
      "Epoch: 198\n",
      "Epoch: 199\n",
      "Przewidywana wartość: 834.1890869140625\n",
      "Rzeczywista wartość: 874.5499877929688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Ustawienie optymalnych hiperparametrów\n",
    "optimal_hidden_dim = int(best['hidden_dim'])\n",
    "optimal_dropout = best['dropout']\n",
    "\n",
    "# Inicjalizacja modelu z optymalnymi hiperparametrami\n",
    "optimal_model = GraphRegressionModel(hidden_dim=optimal_hidden_dim, dropout=optimal_dropout)\n",
    "\n",
    "# Definiuj DataLoader dla zbiorów uczącego i testowego\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Definiuj optymalizator, liczbę epok, itp.\n",
    "optimizer = torch.optim.Adam(optimal_model.parameters(), lr=0.001)\n",
    "num_epochs = 200\n",
    "\n",
    "# Listy do śledzenia train loss i test loss\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Trening modelu\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = optimal_model(data)\n",
    "        loss = optimal_model.loss(output, data.y.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "sample_data = test_dataset[0]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fc4a8c-0a49-4e5e-8fed-c54bb4991be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana wartość: 830.5301513671875\n",
      "Rzeczywista wartość: 860.9299926757812\n"
     ]
    }
   ],
   "source": [
    "sample_data = test_dataset[30]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4e0e9f9-d9b9-487b-a673-1a3ea0cd313c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana wartość: 287.41595458984375\n",
      "Rzeczywista wartość: 286.3299865722656\n"
     ]
    }
   ],
   "source": [
    "sample_data = test_dataset[9]\n",
    "\n",
    "# Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "optimal_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = optimal_model(sample_data)[0][0].item()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Przewidywana wartość:\", prediction)\n",
    "print(\"Rzeczywista wartość:\", sample_data.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5e5f93d-8db8-4a92-8058-f4ce2fa5f729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykład 1:\n",
      "Przewidywana wartość: 834.1890869140625\n",
      "Rzeczywista wartość: 874.5499877929688\n",
      "Procentowa jakość regresji: 95.38%\n",
      "\n",
      "Przykład 2:\n",
      "Przewidywana wartość: 576.5999145507812\n",
      "Rzeczywista wartość: 569.8499755859375\n",
      "Procentowa jakość regresji: 98.82%\n",
      "\n",
      "Przykład 3:\n",
      "Przewidywana wartość: 461.2392578125\n",
      "Rzeczywista wartość: 450.54998779296875\n",
      "Procentowa jakość regresji: 97.63%\n",
      "\n",
      "Przykład 4:\n",
      "Przewidywana wartość: 881.8521118164062\n",
      "Rzeczywista wartość: 839.4600219726562\n",
      "Procentowa jakość regresji: 94.95%\n",
      "\n",
      "Przykład 5:\n",
      "Przewidywana wartość: 702.5387573242188\n",
      "Rzeczywista wartość: 705.010009765625\n",
      "Procentowa jakość regresji: 99.65%\n",
      "\n",
      "Przykład 6:\n",
      "Przewidywana wartość: 687.1488037109375\n",
      "Rzeczywista wartość: 697.9400024414062\n",
      "Procentowa jakość regresji: 98.45%\n",
      "\n",
      "Przykład 7:\n",
      "Przewidywana wartość: 870.410400390625\n",
      "Rzeczywista wartość: 854.9099731445312\n",
      "Procentowa jakość regresji: 98.19%\n",
      "\n",
      "Przykład 8:\n",
      "Przewidywana wartość: 800.1185913085938\n",
      "Rzeczywista wartość: 813.02001953125\n",
      "Procentowa jakość regresji: 98.41%\n",
      "\n",
      "Przykład 9:\n",
      "Przewidywana wartość: 313.1221618652344\n",
      "Rzeczywista wartość: 286.0299987792969\n",
      "Procentowa jakość regresji: 90.53%\n",
      "\n",
      "Przykład 10:\n",
      "Przewidywana wartość: 287.41595458984375\n",
      "Rzeczywista wartość: 286.3299865722656\n",
      "Procentowa jakość regresji: 99.62%\n",
      "\n",
      "Przykład 11:\n",
      "Przewidywana wartość: 636.6835327148438\n",
      "Rzeczywista wartość: 673.02001953125\n",
      "Procentowa jakość regresji: 94.60%\n",
      "\n",
      "Przykład 12:\n",
      "Przewidywana wartość: 188.58734130859375\n",
      "Rzeczywista wartość: 198.0\n",
      "Procentowa jakość regresji: 95.25%\n",
      "\n",
      "Przykład 13:\n",
      "Przewidywana wartość: 868.7130737304688\n",
      "Rzeczywista wartość: 863.3800048828125\n",
      "Procentowa jakość regresji: 99.38%\n",
      "\n",
      "Przykład 14:\n",
      "Przewidywana wartość: 262.591552734375\n",
      "Rzeczywista wartość: 240.9499969482422\n",
      "Procentowa jakość regresji: 91.02%\n",
      "\n",
      "Przykład 15:\n",
      "Przewidywana wartość: 245.71690368652344\n",
      "Rzeczywista wartość: 238.02999877929688\n",
      "Procentowa jakość regresji: 96.77%\n",
      "\n",
      "Przykład 16:\n",
      "Przewidywana wartość: 798.134765625\n",
      "Rzeczywista wartość: 855.3099975585938\n",
      "Procentowa jakość regresji: 93.32%\n",
      "\n",
      "Przykład 17:\n",
      "Przewidywana wartość: 389.4044494628906\n",
      "Rzeczywista wartość: 367.8999938964844\n",
      "Procentowa jakość regresji: 94.15%\n",
      "\n",
      "Przykład 18:\n",
      "Przewidywana wartość: 602.3310546875\n",
      "Rzeczywista wartość: 620.719970703125\n",
      "Procentowa jakość regresji: 97.04%\n",
      "\n",
      "Przykład 19:\n",
      "Przewidywana wartość: 843.0896606445312\n",
      "Rzeczywista wartość: 828.6599731445312\n",
      "Procentowa jakość regresji: 98.26%\n",
      "\n",
      "Przykład 20:\n",
      "Przewidywana wartość: 488.8903503417969\n",
      "Rzeczywista wartość: 485.5199890136719\n",
      "Procentowa jakość regresji: 99.31%\n",
      "\n",
      "Przykład 21:\n",
      "Przewidywana wartość: 294.8210144042969\n",
      "Rzeczywista wartość: 291.5199890136719\n",
      "Procentowa jakość regresji: 98.87%\n",
      "\n",
      "Przykład 22:\n",
      "Przewidywana wartość: 346.6177978515625\n",
      "Rzeczywista wartość: 325.3299865722656\n",
      "Procentowa jakość regresji: 93.46%\n",
      "\n",
      "Przykład 23:\n",
      "Przewidywana wartość: 409.6965026855469\n",
      "Rzeczywista wartość: 382.94000244140625\n",
      "Procentowa jakość regresji: 93.01%\n",
      "\n",
      "Przykład 24:\n",
      "Przewidywana wartość: 438.1330871582031\n",
      "Rzeczywista wartość: 416.5400085449219\n",
      "Procentowa jakość regresji: 94.82%\n",
      "\n",
      "Przykład 25:\n",
      "Przewidywana wartość: 906.2385864257812\n",
      "Rzeczywista wartość: 895.22998046875\n",
      "Procentowa jakość regresji: 98.77%\n",
      "\n",
      "Przykład 26:\n",
      "Przewidywana wartość: 958.824462890625\n",
      "Rzeczywista wartość: 903.760009765625\n",
      "Procentowa jakość regresji: 93.91%\n",
      "\n",
      "Przykład 27:\n",
      "Przewidywana wartość: 827.7879638671875\n",
      "Rzeczywista wartość: 816.4500122070312\n",
      "Procentowa jakość regresji: 98.61%\n",
      "\n",
      "Przykład 28:\n",
      "Przewidywana wartość: 862.19580078125\n",
      "Rzeczywista wartość: 858.4500122070312\n",
      "Procentowa jakość regresji: 99.56%\n",
      "\n",
      "Przykład 29:\n",
      "Przewidywana wartość: 787.8715209960938\n",
      "Rzeczywista wartość: 806.6900024414062\n",
      "Procentowa jakość regresji: 97.67%\n",
      "\n",
      "Przykład 30:\n",
      "Przewidywana wartość: 210.07562255859375\n",
      "Rzeczywista wartość: 200.39999389648438\n",
      "Procentowa jakość regresji: 95.17%\n",
      "\n",
      "Przykład 31:\n",
      "Przewidywana wartość: 830.5301513671875\n",
      "Rzeczywista wartość: 860.9299926757812\n",
      "Procentowa jakość regresji: 96.47%\n",
      "\n",
      "Przykład 32:\n",
      "Przewidywana wartość: 891.6096801757812\n",
      "Rzeczywista wartość: 898.5999755859375\n",
      "Procentowa jakość regresji: 99.22%\n",
      "\n",
      "Przykład 33:\n",
      "Przewidywana wartość: 800.7440795898438\n",
      "Rzeczywista wartość: 786.8599853515625\n",
      "Procentowa jakość regresji: 98.24%\n",
      "\n",
      "Przykład 34:\n",
      "Przewidywana wartość: 477.6459045410156\n",
      "Rzeczywista wartość: 463.6000061035156\n",
      "Procentowa jakość regresji: 96.97%\n",
      "\n",
      "Przykład 35:\n",
      "Przewidywana wartość: 664.0677490234375\n",
      "Rzeczywista wartość: 640.3599853515625\n",
      "Procentowa jakość regresji: 96.30%\n",
      "\n",
      "Przykład 36:\n",
      "Przewidywana wartość: 936.4877319335938\n",
      "Rzeczywista wartość: 979.5999755859375\n",
      "Procentowa jakość regresji: 95.60%\n",
      "\n",
      "Przykład 37:\n",
      "Przewidywana wartość: 195.85824584960938\n",
      "Rzeczywista wartość: 197.47000122070312\n",
      "Procentowa jakość regresji: 99.18%\n",
      "\n",
      "Przykład 38:\n",
      "Przewidywana wartość: 703.8026733398438\n",
      "Rzeczywista wartość: 678.4500122070312\n",
      "Procentowa jakość regresji: 96.26%\n",
      "\n",
      "Przykład 39:\n",
      "Przewidywana wartość: 400.3258056640625\n",
      "Rzeczywista wartość: 368.6300048828125\n",
      "Procentowa jakość regresji: 91.40%\n",
      "\n",
      "Przykład 40:\n",
      "Przewidywana wartość: 243.45547485351562\n",
      "Rzeczywista wartość: 246.77999877929688\n",
      "Procentowa jakość regresji: 98.65%\n",
      "\n",
      "Przykład 41:\n",
      "Przewidywana wartość: 599.9741821289062\n",
      "Rzeczywista wartość: 588.5499877929688\n",
      "Procentowa jakość regresji: 98.06%\n",
      "\n",
      "Przykład 42:\n",
      "Przewidywana wartość: 873.4169921875\n",
      "Rzeczywista wartość: 891.1699829101562\n",
      "Procentowa jakość regresji: 98.01%\n",
      "\n",
      "Przykład 43:\n",
      "Przewidywana wartość: 961.0892944335938\n",
      "Rzeczywista wartość: 916.719970703125\n",
      "Procentowa jakość regresji: 95.16%\n",
      "\n",
      "Przykład 44:\n",
      "Przewidywana wartość: 574.576904296875\n",
      "Rzeczywista wartość: 551.02001953125\n",
      "Procentowa jakość regresji: 95.72%\n",
      "\n",
      "Przykład 45:\n",
      "Przewidywana wartość: 511.0352783203125\n",
      "Rzeczywista wartość: 501.6300048828125\n",
      "Procentowa jakość regresji: 98.13%\n",
      "\n",
      "Przykład 46:\n",
      "Przewidywana wartość: 754.2468872070312\n",
      "Rzeczywista wartość: 778.0399780273438\n",
      "Procentowa jakość regresji: 96.94%\n",
      "\n",
      "Średnia procentowa jakość regresji dla wszystkich przykładów: 96.63%\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = 0.0\n",
    "\n",
    "# Iteracja przez cały zbiór testowy\n",
    "for i, sample_data in enumerate(test_dataset):\n",
    "    # Przeprowadzenie predykcji na przykładowym obiekcie\n",
    "    optimal_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = optimal_model(sample_data)[0][0].item()\n",
    "    \n",
    "    # Wyświetlenie wyników\n",
    "    print(f\"Przykład {i + 1}:\")\n",
    "    print(\"Przewidywana wartość:\", prediction)\n",
    "    print(\"Rzeczywista wartość:\", sample_data.y.item())\n",
    "    \n",
    "    # Obliczenie procentowej jakości regresji\n",
    "    actual_value = sample_data.y.item()\n",
    "    accuracy = 100 * (1 - abs(prediction - actual_value) / actual_value)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "    print(f\"Procentowa jakość regresji: {accuracy:.2f}%\\n\")\n",
    "\n",
    "# Obliczenie średniej jakości procentowej\n",
    "average_accuracy = total_accuracy / len(test_dataset)\n",
    "print(f\"Średnia procentowa jakość regresji dla wszystkich przykładów: {average_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175333d-a83a-4a99-a172-800e4856b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
