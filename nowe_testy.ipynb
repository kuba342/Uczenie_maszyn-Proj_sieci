{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'device')\n",
    "\n",
    "# Wczytaj zbiór uczący\n",
    "train_dataset = torch.load('train_dataset.pt')\n",
    "# wczytaj zbiór testowy\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "# Definiuj DataLoader dla zbiorów uczącego i testowego\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChGW0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0988f0d7-c3fd-4b9e-9f78-82eb318c7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "        name = 'ChGW0'\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)  # Dostosuj global_feature do rozmiaru x\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]/tmp/ipykernel_24189/2804048419.py:40: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred, score)\n",
      "Epoch: 100%|██████████| 50/50 [00:09<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 56229.4624691165\n",
      "Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 50/50 [00:10<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 50692.229821246605\n",
      "Fold 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 48/50 [00:09<00:00,  5.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/franek/05-12_code/nowe_testy.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss(output, data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/franek/05-12_code/nowe_testy.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x, edge_index, edge_weight, global_feature \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39medge_weight, data\u001b[39m.\u001b[39mglobal_feature\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Apply Graph Convolution\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index, edge_weight\u001b[39m=\u001b[39medge_weight)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Global features concatenation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franek/05-12_code/nowe_testy.ipynb#X51sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m global_feature \u001b[39m=\u001b[39m global_feature\u001b[39m.\u001b[39mexpand(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Dostosuj global_feature do rozmiaru x\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/graph_conv.py:86\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     83\u001b[0m     x: OptPairTensor \u001b[39m=\u001b[39m (x, x)\n\u001b[1;32m     85\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[1;32m     87\u001b[0m                      size\u001b[39m=\u001b[39msize)\n\u001b[1;32m     88\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_rel(out)\n\u001b[1;32m     90\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:487\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         out \u001b[39m=\u001b[39m res\n\u001b[0;32m--> 487\u001b[0m update_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[1;32m    488\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mupdate_kwargs)\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m decomposed_layers \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/utils/inspector.py:52\u001b[0m, in \u001b[0;36mInspector.distribute\u001b[0;34m(self, func_name, kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             out[key] \u001b[39m=\u001b[39m arg_types[key]\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m---> 52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdistribute\u001b[39m(\u001b[39mself\u001b[39m, func_name, kwargs: Dict[\u001b[39mstr\u001b[39m, Any]):\n\u001b[1;32m     53\u001b[0m     out \u001b[39m=\u001b[39m {}\n\u001b[1;32m     54\u001b[0m     \u001b[39mfor\u001b[39;00m key, param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[func_name]\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import your GraphRegressionModel here...\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'device')\n",
    "\n",
    "# Load your training and test datasets\n",
    "train_dataset = torch.load('train_dataset.pt')\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "\n",
    "# Combine the datasets into a single list for cross-validation\n",
    "all_datasets = train_dataset + test_dataset\n",
    "\n",
    "# Convert the combined datasets to PyTorch DataLoader for batch training\n",
    "dataloader = DataLoader(all_datasets, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Training loop for cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_datasets)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    train_data = [all_datasets[i] for i in train_idx]\n",
    "    val_data = [all_datasets[i] for i in val_idx]\n",
    "\n",
    "    # Initialize a new model for each fold\n",
    "    model = GraphRegressionModel().to(device)\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "        for data in train_data:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Send data to the device\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in val_data:\n",
    "            # Send data to the device\n",
    "            data = data.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            val_loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    # Calculate and print the average validation loss for the fold\n",
    "    avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "                with  open('chkgw0_spec.txt', 'w') as file2:\n",
    "                    file2.write('\\n'+f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {mse}, R2: {r2}\", file=file2)\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "            # Open files for writing\n",
    "            with open('chkgw0_avg.txt', 'w') as file1:\n",
    "                # Print the results to file1\n",
    "                     file1.write('\\n'+\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {avg_mse}, Avg R2: {avg_r2}\", file=file1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model podstawowy, ale bez dropout'u - chyba najlepszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, momentum=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers (without Dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers (without Dropout)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('noDrop_avg.txt', 'w') as file1, open('noDrop_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model podstawowy bez cech globalnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('noGlob_avg.txt', 'w') as file1, open('noGlob_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChGW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphRegressionModelGCN(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModelGCN, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer using GCNConv\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution using GCNConv\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('chkgw1_avg.txt', 'w') as file1, open('chkgw1_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChGW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "class GraphRegressionModelCheb(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModelCheb, self).__init__()\n",
    "\n",
    "        # Chebyshev Graph Convolutional Layer\n",
    "        self.conv1 = ChebConv(num_node_features, hidden_dim, K=2)  # K is the filter size (you can adjust it)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Chebyshev Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('chkgw2_avg.txt', 'w') as file1, open('chkgw2_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EdgeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, EdgeConv\n",
    "\n",
    "class CustomEdgeConv(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim):\n",
    "        super(CustomEdgeConv, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(1, 32),  # Adjust the input size for the first linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, hidden_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        #self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "\n",
    "        # Edge Convolutional Layer\n",
    "        self.conv2 = CustomEdgeConv(num_node_features, hidden_dim+2)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 4, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        #x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        # Apply Edge Convolution\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('edgeConv_avg.txt', 'w') as file1, open('edgeConv_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "    \n",
    "\n",
    "class GraphRegressionModel(nn.Module):\n",
    "    def __init__(self, num_node_features=1, hidden_dim=64, output_dim=1, dropout=0.5, momentum=0.5):\n",
    "        super(GraphRegressionModel, self).__init__()\n",
    "\n",
    "        # Graph Convolutional Layer\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        self.fc1 = nn.Linear(hidden_dim + 2, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Store momentum as an attribute\n",
    "        self.momentum = momentum\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, global_feature = data.x, data.edge_index, data.edge_weight, data.global_feature\n",
    "\n",
    "        # Apply Graph Convolution\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "\n",
    "        # Global features concatenation\n",
    "        global_feature = global_feature.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "\n",
    "        # Fully Connected Layers with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, score):\n",
    "        return F.mse_loss(pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter values to test\n",
    "hidden_dim_values = list(range(16, 512, 16))\n",
    "dropout_values = np.arange(0.05, 1.0, 0.05)\n",
    "momentum_values = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "part_results ={}\n",
    "results = {}\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for dropout in dropout_values:\n",
    "        for momentum in momentum_values:\n",
    "            print(f\"\\nTesting for hidden_dim={hidden_dim}, dropout={dropout}, momentum={momentum}\")\n",
    "\n",
    "            # Initialize a dictionary to store results for the current hyperparameters\n",
    "            hyperparam_results = {'MSE': [], 'R2': []}\n",
    "\n",
    "            # Loop over folds\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                train_data = [train_dataset[i] for i in train_idx]\n",
    "                val_data = [train_dataset[i] for i in val_idx]\n",
    "\n",
    "                model = GraphRegressionModel(num_node_features=1, hidden_dim=hidden_dim, output_dim=1, dropout=dropout, momentum=momentum)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                for epoch in tqdm(range(10), desc=f\"Fold {fold + 1}/{num_folds}\"):\n",
    "                    for data in train_data:\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(data)\n",
    "                        loss = model.loss(output, data.y.view(-1, 1).float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for data in val_data:\n",
    "                    with torch.no_grad():    \n",
    "                        output = model(data)[0][0].item()                \n",
    "                        y_pred.append(output)\n",
    "\n",
    "                    y_true.append(data.y.item())\n",
    "\n",
    "                # Calculate and store Mean Squared Error (MSE)\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                hyperparam_results['R2'].append(r2)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                hyperparam_results['MSE'].append(mse)\n",
    "                part_results[(hidden_dim, dropout, momentum, fold)] = {'MSE': mse, 'R2' : r2}\n",
    "\n",
    "            # Calculate average MSE across folds\n",
    "            avg_mse = sum(hyperparam_results['MSE']) / num_folds\n",
    "            avg_r2 = sum(hyperparam_results['R2']) / num_folds\n",
    "            results[(hidden_dim, dropout, momentum)] = {'Avg MSE': avg_mse, 'Avg R2': avg_r2}\n",
    "\n",
    "\n",
    "# Open files for writing\n",
    "with open('GCN_avg.txt', 'w') as file1, open('GCN_spec.txt', 'w') as file2:\n",
    "    # Print the results to file1\n",
    "    for (hidden_dim, dropout), metrics in results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Avg MSE: {metrics['Avg MSE']}, Avg R2: {metrics['Avg R2']}\", file=file1)\n",
    "\n",
    "    # Print the partial results to file2\n",
    "    for (hidden_dim, dropout, fold), metrics in part_results.items():\n",
    "        print(f\"Hidden Dim: {hidden_dim}, Dropout: {dropout}, Momentum: {momentum}, Fold: {fold}, MSE: {metrics['MSE']}, R2: {metrics['R2']}\", file=file2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
